---
keywords: Experience Platform;walkthrough;Data Science Workspace;popular topics
solution: Experience Platform
title: Data Science Workspaceのチュートリアル
topic: Walkthrough
translation-type: tm+mt
source-git-commit: 1f756e7bc71c9ff227757aee64af29e0772c24af

---


# Data Science Workspaceのチュートリアル

このドキュメントでは、Adobe Experience Platform Data Science Workspaceのチュートリアルを提供します。 具体的には、データサイエンティストが扱う一般的なワークフローを調べ、機械学習を使用した問題の解決に取り組みます。

## 前提条件

- 登録済みのAdobe IDアカウント
   - Adobe IDアカウントは、Adobe Experience PlatformおよびData Science Workspaceへのアクセス権を持つ組織に追加されている必要があります

## データサイエンティストの動機

現在の市場での競争力を維持するために、ある小売業者は多くの課題に直面しています。 小売業者の主な懸念事項の1つは、商品の最適価格を決定し、販売傾向を予測することです。 正確な予測モデルを使用すると、小売業者は、需要と価格設定ポリシーの関係を見つけ出し、販売と売上高を最大化するために最適化された価格決定を行うことができます。

## データサイエンティストの解

データサイエンティストのソリューションは、小売業者がアクセスできる豊富な履歴データを活用し、将来の傾向を予測し、価格決定を最適化することです。 過去の販売データを使って機械学習モデルを訓練し、モデルを使って将来の販売傾向を予測します。 これにより、小売業者は価格を変更する際に役立つ洞察を得ることができます。

この概要では、データサイエンティストがデータセットを取得し、週別の売上を予測するモデルを作成する手順を説明します。 Adobe Experience Platform Data Science Workspaceのサンプル小売売上ノートブックの以下の節を参照します。

- [セットアップ](#setup)
- [データの調査](#exploring-data)
- [機能エンジニアリング](#feature-engineering)
- [トレーニングと検証](#training-and-verification)

### Data Science Workspaceのノートブック

まず、JupyterLabノートブックを作成し、「小売売上」サンプルノートブックを開きます。 ノートブック内のデータサイエンティストが行った手順に従うことで、一般的なワークフローを理解できます。

Adobe Experience Platform UIで、上部メニューの「データサイエンス」タブをクリックし、Data Science Workspaceに移動します。 このページで、「JupyterLab」タブをクリックし、JupyterLabランチャーを開きます。 次のようなページが表示されます。

![](./images/walkthrough/jupyterlab_launcher.png)

このチュートリアルでは、Jupyter NotebookのPython 3を使用して、データにアクセスして調査する方法を示します。 ランチャーページには、サンプルのノートブックが用意されています。 Python 3用の「小売売上」サンプルを使用します。

![](./images/walkthrough/retail_sales.png)

### セットアップ

小売売上ノートブックを開いた状態で、まずワークフローに必要なライブラリを読み込みます。 次のリストでは、それぞれの用途について簡単に説明します。
- **numpy** — 大きな多次元配列と行列のサポートを追加する科学計算ライブラリ
- **pandas** — データの操作と分析に使用するデータ構造と操作をオファーするライブラリ
- **matplotlib.pyplot** — 印刷時にMATLABと同じような操作を行う印刷ライブラリ
- **seaborn** - matplotlibに基づく高レベルのインターフェイスデータ視覚化ライブラリ
- **sklearn** — 分類、回帰、サポートベクトルおよびクラスターアルゴリズムを備えた機械学習ライブラリ
- **warnings** — 警告メッセージを制御するライブラリ

### データの調査

#### データの読み込み

ライブラリの読み込み後、データを開始で確認できます。 次のPythonコードは、pandasのデータ構 `DataFrame` 造と [read_csv()関数を使用して](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html#pandas.read_csv) 、GithubでホストされるCSVをpandas DataFrameに読み込みます。

![](./images/walkthrough/read_csv.png)

PandasのDataFrameデータ構造は、2次元のラベル付きデータ構造です。 データの次元をすばやく確認するには、を使用しま `df.shape`す。 DataFrameの次元を表すタプルが返されます。

![](./images/walkthrough/df_shape.png)

最後に、データがどのように見えるかを見てみましょう。 を使用して、DataFrame `df.head(n)` の最初の行を `n` 表示できます。

![](./images/walkthrough/df_head.png)

#### 統計概要

Pythonのパンダライブラリを利用して、各属性のデータ型を取得できます。 次の呼び出しの出力では、各列のエントリ数とデータタイプに関する情報が得られます。

```PYTHON
df.info()
```

![](./images/walkthrough/df_info.png)

この情報は、各列のデータタイプを知ることで、データの処理方法を知ることができるので役に立ちます。

次に、統計の概要を見てみましょう。 数値データ型のみが表示され、 `date`、お `storeType`よびは `isHoliday` 出力されません。

```PYTHON
df.describe()
```

![](./images/walkthrough/df_describe.png)

これにより、各特性に対して6435個のインスタンスが存在することがわかります。 また、平均、標準偏差(std)、最小、最大、四分位数などの統計情報も表示されます。 これにより、データの偏差に関する情報が得られます。 次の節では、この情報と連携して機能するビジュアライゼーションを見て、データを完全に理解していきます。

の最小値と最大値を見ると、デ `store`ータが表す一意のストアが45個あることがわかります。 店とは何かを区 `storeTypes` 別する店もある。 の配布は、次の方法で確 `storeTypes` 認できます。

![](./images/walkthrough/df_groupby.png)

つまり、22店舗が、 `storeType A` 17店舗、 `storeType B`6店舗である `storeType C`。

#### データの視覚化

データフレームの値がわかったので、パターンをより明確にし、より簡単に識別できるように、ビジュアライゼーションを使用してこれを補完したいと考えています。 これらのグラフは、結果をオーディエンスに伝える場合にも便利です。

#### 一変グラフ

一変量グラフは、個々の変数のグラフです。 データの視覚化に使用される一般的な一変量グラフは、ボックスグラフとウィスカーグラフです。

以前の小売データセットを使って、45店舗とその週間販売のそれぞれの箱ひげ図を作成できます。 プロットは、関数を使用して生成さ `seaborn.boxplot` れます。

![](./images/walkthrough/box_whisker.png)

ボックスとウィスカープロットは、データの分布を示すのに使用されます。 プロットの外側の線は上下の四分位数を示し、ボックスは四分位数の範囲に及びます。 ボックス内の行は中央値を示します。 上四分位数または下四分位数の1.5倍以上のデータポイントは、円としてマークされます。 これらの点は外れ値と見なされます。

次に、週別の売り上げを時間と共にプロットします。 私たちはファーストストアの出力のみを表示します。 ノートブック内のコードは、データセット内の45店舗のうち6店舗に対応する6プロットを生成します。

![](./images/walkthrough/weekly_sales.png)

この図では、2年間の週別売上高を比較できます。 販売のピークやトラフのパターンが時間の経過と共に見えやすくなります。

#### 多変量分析グラフ

多変量分析プロットは、変数間の相互作用を確認するために使用されます。 このビジュアライゼーションを使用すると、データ科学者は変数間に相関関係やパターンがあるかどうかを確認できます。 一般的な多変量分析グラフは、相関行列です。 相関行列を用いて、相関係数を用いて複数の変数間の依存関係を定量化する。

同じ小売データセットを使用して、相関行列を生成できます。

![](./images/walkthrough/correlation_1.png)

斜めの斜めが中央から下にあることに注目してください。 これは、変数をそれ自体と比較する場合、完全に正の相関関係があることを示しています。 強い正の相関は1に近い大きさになり、弱い相関は0に近い大きさになります。 負の相関は、逆の傾向を示す負の係数で示されます。

### 機能エンジニアリング

この節では、小売データセットを変更します。 我々は以下の業務を行う。

- 週と年の列の追加
- storeTypeをインジケーター変数に変換
- isHolidayを数値変数に変換
- 来週の売り上げを予測する

#### 週追加と年の列

日付()の現在の形式では、`2010-02-05`週ごとのデータを区別するのが困難です。 このため、日付を週と年に変換します。

![](./images/walkthrough/date_to_week_year.png)

現在は、週と日付は次のようになります。

![](./images/walkthrough/date_week_year.png)

#### storeTypeをインジケーター変数に変換

次に、storeType列を各列を表す列に変換します `storeType`。 ストアのタイプは(、`A`、 `B``C`)の3つで、ここから新しい列を作成します。 各列に設定された値はboolean値になり、その他の2列に対して「1」 `storeType` が設 `0` 定されます。

![](./images/walkthrough/storeType.png)

現在の列 `storeType` は削除されます。

#### isHolidayを数値型に変換

次の修正は、ブール値を数値表 `isHoliday` 現に変更することです。

![](./images/walkthrough/isHoliday.png)


#### 来週の売上を予測

次に、各データセットに、前週の売上高と将来の週の売上高を追加します。 我々は、我々を怒らせることでこれを行ってい `weeklySales`る。 さらに、差を計算してい `weeklySales` ます。 これは、前の週の値 `weeklySales` を引くことで行われます `weeklySales`。

![](./images/walkthrough/weekly_past_future.png)

データ45データセットを前方に `weeklySales` 、45データセットを後方にオフセットして新しい列を作成するので、最初と最後の45データポイントにはNaN値が設定されます。 NaN値を持つすべての行を削除する関数を使用して、こ `df.dropna()` れらのポイントをデータセットから削除できます。

![](./images/walkthrough/dropna.png)

次に、変更後のデータセットの概要を示します。

![](./images/walkthrough/df_info_new.png)

### トレーニングと検証

次に、データの一部のモデルを作成し、将来の売上を予測するのに最もパフォーマンスの高いモデルを選択します。 以下の5つのアルゴリズムを評価します。

- 線形回帰
- デシジョンツリー
- ランダムフォレスト
- グラデーションの拡大
- K近隣諸国

#### データセットのトレーニングおよびテストサブセットへの分割

モデルがどの程度正確に値を予測できるかを知る方法が必要です この評価は、検証として使用するデータセットの一部を割り当て、残りをトレーニングデータとして割り当てることで行うことができます。 はの実 `weeklySalesAhead` 際の将来値なので、こ `weeklySales`の値を使用して、モデルが値を予測する際の正確さを評価できます。 分割は次の手順で行います。

![](./images/walkthrough/split_data.png)

これで、モデルの `X_train` 準備と `y_train` 後での評価を行うた `X_test` めの、と `y_test` いうことができます。

#### スポットチェックアルゴリズム

この節では、すべてのアルゴリズムをという配列に宣言しま `model`す。 次に、この配列を繰り返し処理し、各アルゴリズムに対して、モデルを作成するトレーニングデ `model.fit()` ータを入力しま `mdl`す。 このモデルを使って、私たちのデータを `weeklySalesAhead` 使って予測 `X_test` する。

![](./images/walkthrough/training_scoring.png)

スコアリングの場合、予測された値とデータ内の実際の値との間の `weeklySalesAhead` 平均パーセント差を取り `y_test` ます。 予測と実際の差を最小に抑えたいので、グラデーション昇圧回帰は最もパフォーマンスの高いモデルです。

#### 予測の視覚化

最後に、予測モデルを実際の週別の売上高値で視覚化します。 青い線は実際の数を表し、緑はグラデーションの倍率を使用した予測を表します。 次のコードは、データセット内の45店舗のうち6店舗を表す6プロットを生成します。 次の場 `Store 1` 所にのみ表示：

![](./images/walkthrough/visualize_prediction.png)

<!--TODO UI Flow> -->

## まとめ

この概要を踏まえて、データサイエンティストが小売売上の問題を解決するために行うワークフローを調べました。 具体的には、次の手順を実行し、将来の週別売上高を予測するソリューションを実現しました。

- [セットアップ](#setup)
- [データの調査](#exploring-data)
- [機能エンジニアリング](#feature-engineering)
- [トレーニングと検証](#training-and-verification)