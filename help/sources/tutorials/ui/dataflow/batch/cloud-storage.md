---
keywords: Experience Platform;home;popular topics
solution: Experience Platform
title: UIでのクラウドストレージバッチコネクタのデータフローの設定
topic: overview
translation-type: tm+mt
source-git-commit: dca1accc16395de72db6d0cc8eac78f07dd05e03
workflow-type: tm+mt
source-wordcount: '1207'
ht-degree: 1%

---


# UIでのクラウドストレージバッチコネクタのデータフローの設定

データフローとは、ソースからプラットフォームデータセットにデータを取得し、取り込むスケジュール設定されたタスクです。 このチュートリアルでは、クラウドストレージベースのコネクタを使用して新しいデータフローを設定する手順を説明します。

## はじめに

このチュートリアルでは、Adobe Experience Platformの次のコンポーネントについて、十分に理解している必要があります。

* [Experience Data Model(XDM)System](../../../../../xdm/home.md): エクスペリエンスプラットフォームが顧客エクスペリエンスデータを編成する際に使用する標準化されたフレームワークです。
   * [スキーマ構成の基本](../../../../../xdm/schema/composition.md): XDMスキーマの基本構成要素について説明します。この基本構成要素には、スキーマ構成における主な原則とベストプラクティスが含まれます。
   * [スキーマエディタのチュートリアル](../../../../../xdm/tutorials/create-schema-ui.md): スキーマエディターのUIを使用してカスタムスキーマを作成する方法を説明します。
* [リアルタイム顧客プロファイル](../../../../../profile/home.md): 複数のソースからの集計データに基づいて、統合されたリアルタイムの消費者プロファイルを提供します。

また、このチュートリアルでは、クラウドストレージコネクタを既に作成済みである必要があります。 UIで異なるクラウドストレージコネクタを作成するためのチュートリアルのリストは、 [ソースコネクタの概要](../../../../home.md)。

### サポートされているファイル形式

Experience Platformは、次のファイル形式をサポートしており、外部ストレージから取り込むことができます。

* 区切り文字区切り値(DSV): DSV形式のデータ・ファイルのサポートは、現在、コンマ区切り値に制限されています。 DSV形式のファイル内のフィールド・ヘッダーの値は、英数字とアンダースコアのみで構成する必要があります。 一般的なDSVファイルは、今後サポートされる予定です。
* JavaScript Object Notation (JSON): JSON形式のデータファイルは、XDMに準拠している必要があります。
* Apacheパーケット： パーケット形式のデータファイルは、XDMに準拠している必要があります。

## データの選択

クラウドストレージコネクタを作成すると、 *データの選択* 手順が表示され、クラウドストレージ階層を調べるためのインタラクティブインターフェイスが提供されます。

* インターフェイスの左半分はディレクトリブラウザーで、サーバーのファイルとディレクトリが表示されます。
* インターフェイスの右半分を使用すると、互換性のあるファイルから最大100行のデータをプレビューできます。

一覧のフォルダーをクリックすると、フォルダー階層を深いフォルダーに移動できます。 互換性のあるファイルまたはフォルダを選択すると、[ **データ形式の選択** ]ドロップダウンが表示され、プレビューウィンドウにデータを表示する形式を選択できます。

![](../../../../images/tutorials/dataflow/cloud-storage/batch/select-data.png)

プレビューーウィンドウが設定されたら、「 **次へ** 」をクリックして、選択したフォルダー内のすべてのファイルをアップロードできます。 特定のファイルにアップロードする場合は、「 **次へ**」をクリックする前に、リストからそのファイルを選択します。

>[!NOTE] サポートされるファイル形式は、CSV、JSON、Parketです。 JSONファイルとParketファイルは、XDMに準拠している必要があります。

![](../../../../images/tutorials/dataflow/cloud-storage/batch/select-data-next.png)

## データフィールドのXDMスキーマへのマッピング

「 *マッピング* 」の手順が表示され、ソースデータをプラットフォームデータセットにマッピングするためのインタラクティブなインターフェイスが提供されます。 JSONまたはParket形式のソースファイルはXDMに準拠している必要があり、手動でマッピングを設定する必要はありません。 逆に、CSVファイルでは、マッピングを明示的に設定する必要がありますが、マッピングするソースデータフィールドを選択できます。

取り込む受信データのデータセットを選択します。 既存のデータセットを使用することも、新しいデータセットを作成することもできます。

**既存のデータセットの使用**

既存のデータセットにデータを取り込むには、「 **Use existing dataset**」を選択し、データセットアイコンをクリックします。

![](../../../../images/tutorials/dataflow/cloud-storage/batch/use-existing-data.png)

[ _データセットの選択_ ]ダイアログが表示されます。 使用するデータセットを見つけて選択し、「 **続行**」をクリックします。

![](../../../../images/tutorials/dataflow/cloud-storage/batch/select-existing-data.png)

**新しいデータセットの使用**

データを新しいデータセットに取り込むには、「 **新しいデータセットを** 作成」を選択し、表示されるフィールドにデータセットの名前と説明を入力します。 次に、スキーマアイコンをクリックします。

![](../../../../images/tutorials/dataflow/cloud-storage/batch/use-new-schema.png)

[ _スキーマの_ 選択]ダイアログが表示されます。 新しいデータセットに適用するスキーマを選択し、「 **完了**」をクリックします。

![](../../../../images/tutorials/dataflow/cloud-storage/batch/select-schema.png)

必要に応じて、フィールドを直接マップするか、マッパー関数を使用してソースデータを変換し、計算値や計算値を抽出することができます。 データマッピングおよびマッパーの機能について詳しくは、CSVデータのXDMスキーマフィールドへの [マッピングに関するチュートリアルを参照してください](../../../../../ingestion/tutorials/map-a-csv-file.md)。

ソースデータがマッピングされたら、「 **次へ**」をクリックします。

![](../../../../images/tutorials/dataflow/cloud-storage/batch/mapping.png)

## インジェストのスケジュール設定

[ *スケジュール* ]ステップが表示され、設定済みのマッピングを使用して選択したソースデータを自動的に取り込むように取り込みスケジュールを設定できます。 次の表に、スケジュール設定用の様々な設定可能フィールドの概要を示します。

| フィールド | 説明 |
| --- | --- |
| 頻度 | 選択可能な頻度には、分、時間、日、週があります。 |
| 間隔 | 選択した頻度の間隔を設定する整数。 |
| 開始時間 | 最初の取り込みが行われるUTCタイムスタンプ。 |
| 埋め戻し | 最初に取り込まれるデータを決定するboolean値です。 [ *バックフィル* ]を有効にすると、指定したパスにある現在のファイルは、最初にスケジュールされた取り込み中にすべて取り込まれます。 [ *バックフィル* ]を無効にすると *、最初の取り込み実行から* 開始時間の間に読み込まれたファイルだけが取り込まれます。 *開始時間より前に読み込まれたファイルは取り込まれません* 。 |

データフローは、スケジュールに基づいてデータを自動的に取り込むように設計されています。 このワークフローで1回だけ取り込む場合は、 **頻度** 「日」を設定し、 ****&#x200B;間隔に非常に大きな数値（例：10000）を適用することで、これを行うことができます。

スケジュールの値を指定し、「 **次へ**」をクリックします。

![](../../../../images/tutorials/dataflow/cloud-storage/batch/scheduling.png)

## データフローに名前を付ける

「 *名前フロー* 」ステップが表示され、新しいデータフローに名前を付け、簡単に説明を付けることができます。

データフローの値を指定し、「 **次へ**」をクリックします。

![](../../../../images/tutorials/dataflow/cloud-storage/batch/name-your-dataflow.png)

### データフローの確認

「 *レビュー* 」ステップが表示され、新しいデータフローを作成前に確認できます。 詳細は次のカテゴリに分類されます。

* *ソースの詳細*: ソースの種類、選択したソースファイルの関連パス、およびそのソースファイル内の列数が表示されます。
* *ターゲットの詳細*: ソースデータが取り込まれるデータセット(データセットに従うスキーマなど)を示します。
* *スケジュールの詳細*: 取り込みスケジュールの有効期間、頻度、間隔を表示します。

データフローをレビューしたら、 **「Finish** 」をクリックし、データフローを作成するまでの時間を設定します。

![](../../../../images/tutorials/dataflow/cloud-storage/batch/review.png)

## データフローの監視

クラウドストレージのデータフローが作成されたら、データを通じて取り込まれるデータを監視できます。 データセットの監視の詳細については、「ストリーミングデータフローの [監視に関するチュートリアル](../../../../../ingestion/quality/monitor-data-flows.md)」を参照してください。

## 次の手順

このチュートリアルに従うと、外部のクラウドストレージからデータを取り込むためのデータフローが正しく作成され、データセットの監視に関する洞察が得られます。 受信データは、リアルタイム顧客プロファイルやデータサイエンスワークスペースなどのダウンストリームプラットフォームサービスで使用できるようになりました。 詳しくは、次のドキュメントを参照してください。

* [リアルタイム顧客プロファイルの概要](../../../../../profile/home.md)
* [Data Science Workspaceの概要](../../../../../data-science-workspace/home.md)

## 付録

以下の節では、ソースコネクタを使用する場合の追加情報について説明します。

### データフローの無効化

データフローが作成されると、そのデータはすぐにアクティブになり、指定されたスケジュールに従ってデータを取り込みます。 アクティブなデータフローは、次の手順に従っていつでも無効にできます。

「 *ソース* 」ワークスペース内で、「 **参照** 」タブをクリックします。 次に、無効にするアクティブなデータフローに関連付けられているアカウントの名前をクリックします。

![](../../../../images/tutorials/dataflow/cloud-storage/batch/browse.png)

「 *ソースアクティビティ* 」ページが表示されます。 リストからアクティブなデータフローを選択し、画面の右側に *「Properties* 」列を開きます。この列には「 **Enabled** 」トグル・ボタンが含まれています。 切り替えボタンをクリックして、データフローを無効にします。 同じ切り替えを使用して、データフローを無効にした後で再び有効にできます。

![](../../../../images/tutorials/dataflow/cloud-storage/batch/disable-source.png)

### プロファイル母集団の受信データを有効にする

ソースコネクタから受信するデータは、リアルタイム顧客プロファイルデータの強化と埋め込みに使用できます。 実際の顧客プロファイルデータの入力に関する詳細は、 [プロファイル母集団に関するチュートリアルを参照してください](../../profile.md)。
