---
title: 分類アルゴリズム
description: 高度な統計モデルを実装するのに役立つ主要なパラメーター、説明、サンプルコードを使用して、様々な分類アルゴリズムを設定および最適化する方法について説明します。
role: Developer
exl-id: 9105ab04-b480-48a0-b8f7-cf0ed5e5399d
source-git-commit: 489063fcd003e20f233a9c9d85d8cb6c22708d88
workflow-type: tm+mt
source-wordcount: '2449'
ht-degree: 4%

---

# 分類アルゴリズム {#classification-algorithms}

このドキュメントでは、高度な統計モデルでの設定、主要なパラメーター、実際の使用方法に重点を置いて、様々な分類アルゴリズムの概要を説明します。 分類アルゴリズムは、入力特性に基づいてデータポイントにカテゴリを割り当てるために使用されます。 各セクションには、デシジョンツリー、ランダムフォレスト、Naive Bayes 分類などのタスクに対してこれらのアルゴリズムを実装して最適化するのに役立つパラメーターの説明とサンプルコードが含まれています。

## [!DNL Decision Tree Classifier] {#decision-tree-classifier}

[!DNL Decision Tree Classifier] は、統計、データマイニング、機械学習で使用される監視付き学習アプローチです。 このアプローチでは、デシジョンツリーを分類タスクの予測モデルとして使用し、一連の観測から結論を導き出します。

**パラメーター**

次の表に、[!DNL Decision Tree Classifier] ールのパフォーマンスの設定と最適化のための主要なパラメーターの概要を示します。

| パラメーター | 説明 | デフォルト値 | 可能な値 |
|-------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------|------------------|
| `MAX_BINS` | bin の最大数は、連続する機能を個別の間隔に分割する方法を決定します。 これは、各デシジョンツリーノードでの機能の分割方法に影響します。 bin が多いほど、精度が高くなります。 | 32 | 少なくとも 2 で、カテゴリ機能のカテゴリ数と等しい数である必要があります。 |
| `CACHE_NODE_IDS` | `false` の場合、アルゴリズムによってツリーがエグゼキューターに渡され、インスタンスとノードが一致します。 `true` の場合、アルゴリズムはインスタンスごとにノード ID をキャッシュするので、より深いツリーのトレーニングが迅速になります。 | `false` | `true`、`false` |
| `CHECKPOINT_INTERVAL` | キャッシュされたノード ID のチェックポイント頻度を指定します。 例えば、`10` は、キャッシュが 10 回ごとにチェックポイントされることを意味します。 | 10 | （>= 1） |
| `IMPURITY` | 情報ゲインの計算に使用する条件（大文字と小文字を区別しない）。 | 「ジニ」 | `entropy`、`gini` |
| `MAX_DEPTH` | ツリーの最大深度（負でない）。 例えば、depth `0` は 1 つのリーフノードを意味し、depth `1` は 1 つの内部ノードと 2 つのリーフノードを意味します。 | 5 | （>= 0） （範囲：[0,30]） |
| `MIN_INFO_GAIN` | 分割がツリーノードで考慮されるために必要な最小情報利得。 | 0.0 | （>= 0.0） |
| `MIN_WEIGHT_FRACTION_PER_NODE` | 各子が分割の後に持つ必要がある重み付けされたサンプル数の最小割合。 分割によって、いずれかの子の合計重みの割合がこの値を下回った場合、その子は破棄されます。 | 0.0 | （>= 0.0, &lt;= 0.5） |
| `MIN_INSTANCES_PER_NODE` | 分割後に各子に必要なインスタンスの最小数。 分割の結果、この値よりもインスタンス数が少ない場合、分割は破棄されます。 | 1 | （>= 1） |
| `MAX_MEMORY_IN_MB` | ヒストグラム集計に割り当てる最大メモリを MB 単位で指定します。 この値が小さすぎる場合、1 回のイテレーションで分割されるノードは 1 つだけで、その集計はこのサイズを超える可能性があります。 | 256 | （>= 0） |
| `PREDICTION_COL` | 予測出力の列名。 | 「予測」 | 任意の文字列 |
| `SEED` | ランダム シードです。 | なし | 任意の 64 ビット番号 |
| `WEIGHT_COL` | 列名（例：重み）。 設定されていない場合や空の場合は、すべてのインスタンスの重みが `1.0` として扱われます。 | 設定されていません | 任意の文字列 |
| `ONE_VS_REST` | マルチクラス分類の問題に使用される、このアルゴリズムの One-vs-Rest ラッピングを有効または無効にします。 | `false` | `true`、`false` |

{style="table-layout:auto"}

**例**

```sql
Create MODEL modelname OPTIONS(
  type = 'decision_tree_classifier'
) AS
  select col1, col2, col3 from training-dataset
```

## [!DNL Factorization Machine Classifier] {#factorization-machine-classifier}

[!DNL Factorization Machine Classifier] は、通常の勾配降下と AdamW ソルバをサポートする分類アルゴリズムです。 ファクタリング機械分類モデルは、ロジスティック損失を使用します。これは、勾配降下によって最適化でき、多くの場合、オーバーフィットを防ぐために L2 などの正規化用語を含みます。

**パラメーター**

[!DNL Factorization Machine Classifier] のパフォーマンスの設定および最適化のための主要なパラメーターの概要を次の表に示します。

| パラメーター | 説明 | デフォルト値 | 可能な値 |
|------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------|-------------------------------------------------------------------------------------------------------|
| `TOL` | 最適化の精度を制御する収束許容値。 | `1E-6` | （>= 0） |
| `FACTOR_SIZE` | 要因のディメンション。 | 8 | （>= 0） |
| `FIT_INTERCEPT` | インターセプト項をフィットさせるかどうかを指定します。 | `true` | `true`、`false` |
| `FIT_LINEAR` | 線形項（単方向項とも呼ばれます）を適合させるかどうかを指定します。 | `true` | `true`、`false` |
| `INIT_STD` | 係数を初期化するための標準偏差。 | 0.01 | （>= 0） |
| `MAX_ITER` | アルゴリズムを実行する最大反復数。 | 100 | （>= 0） |
| `MINI_BATCH_FRACTION` | トレーニング中にミニバッチで使用するデータの割合。 `(0, 1]` の範囲である必要があります。 | 1.0 | 0 &lt; 値 &lt;= 1 |
| `REG_PARAM` | 正規化パラメーターは、モデルの複雑さを制御し、オーバーフィットを防ぐのに役立ちます。 | 0.0 | （>= 0） |
| `SEED` | アルゴリズム内のランダムプロセスを制御するためのランダムシード。 | なし | 任意の 64 ビット番号 |
| `SOLVER` | 最適化に使用するソルバーアルゴリズム。 サポートされるオプションは、`gd` （グラデーション下降）と `adamW` です。 | 「アダム W」 | `gd`、`adamW` |
| `STEP_SIZE` | 最適化の初期ステップサイズで、多くの場合、学習率と解釈されます。 | 1.0 | > 0 |
| `PROBABILITY_COL` | 予測されるクラスの条件付き確率の列名。 メモ：すべてのモデルが適切に調整された確率を出力するわけではありません。これらは正確な確率ではなく信頼性スコアとして扱う必要があります。 | 「確率」 | 任意の文字列 |
| `PREDICTION_COL` | 予測されるクラスラベルの列名。 | 「予測」 | 任意の文字列 |
| `RAW_PREDICTION_COL` | 生の予測値の列名（信頼性とも呼ばれます）。 | &quot;rawPrediction&quot; | 任意の文字列 |
| `ONE_VS_REST` | マルチクラス分類に対して One-vs-Rest を有効にするかどうかを指定します。 | FALSE | `true`、`false` |

{style="table-layout:auto"}

**例**

```sql
CREATE MODEL modelname OPTIONS(
  type = 'factorization_machines_classifier'
) AS
  SELECT col1, col2, col3 FROM training-dataset
```

## [!DNL Gradient Boosted Tree Classifier] {#gradient-boosted-tree-classifier}

[!DNL Gradient Boosted Tree Classifier] では、分類タスクの精度を向上させるためにデシジョンツリーのアンサンブルを使用し、モデルのパフォーマンスを向上させるために複数のツリーを組み合わせます。

**パラメーター**

[!DNL Gradient Boosted Tree Classifier] のパフォーマンスの設定および最適化のための主要なパラメーターの概要を次の表に示します。

| パラメーター | 説明 | デフォルト値 | 可能な値 |
|-------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------|------------------------------------------------------------------------------------------------------|
| `MAX_BINS` | bin の最大数は、連続する機能を個別の間隔に分割する方法を決定します。 これは、各デシジョンツリーノードでの機能の分割方法に影響します。 bin が多いほど、精度が高くなります。 | 32 | 少なくとも 2 で、カテゴリ機能のカテゴリ数以上である必要があります。 |
| `CACHE_NODE_IDS` | `false` の場合、アルゴリズムによってツリーがエグゼキューターに渡され、インスタンスとノードが一致します。 `true` の場合、アルゴリズムはインスタンスごとにノード ID をキャッシュするので、より深いツリーのトレーニングが迅速になります。 | `false` | `true`、`false` |
| `CHECKPOINT_INTERVAL` | キャッシュされたノード ID のチェックポイント頻度を指定します。 例えば、`10` は、キャッシュが 10 回ごとにチェックポイントされることを意味します。 | 10 | （>= 1） |
| `MAX_DEPTH` | ツリーの最大深度（負でない）。 例えば、depth `0` は 1 つのリーフノードを意味し、depth `1` は 1 つの内部ノードと 2 つのリーフノードを意味します。 | 5 | （>= 0） |
| `MIN_INFO_GAIN` | 分割がツリーノードで考慮されるために必要な最小情報利得。 | 0.0 | （>= 0.0） |
| `MIN_WEIGHT_FRACTION_PER_NODE` | 各子が分割の後に持つ必要がある重み付けされたサンプル数の最小割合。 分割によって、いずれかの子の合計重みの割合がこの値を下回った場合、その子は破棄されます。 | 0.0 | （>= 0.0, &lt;= 0.5） |
| `MIN_INSTANCES_PER_NODE` | 分割後に各子に必要なインスタンスの最小数。 分割の結果、この値よりもインスタンス数が少ない場合、分割は破棄されます。 | 1 | （>= 1） |
| `MAX_MEMORY_IN_MB` | ヒストグラム集計に割り当てる最大メモリを MB 単位で指定します。 この値が小さすぎる場合、1 回のイテレーションで分割されるノードは 1 つだけで、その集計はこのサイズを超える可能性があります。 | 256 | （>= 0） |
| `PREDICTION_COL` | 予測出力の列名。 | 「予測」 | 任意の文字列 |
| `VALIDATION_INDICATOR_COL` | 列名は、各行をトレーニングまたは検証のどちらに使用するかを示します。 値 `false` はトレーニングを示し、`true` は検証を示します。 値が設定されていない場合、デフォルト値は `None` です。 | &quot;None&quot; | 任意の文字列 |
| `RAW_PREDICTION_COL` | 生の予測値の列名（信頼性とも呼ばれます）。 | &quot;rawPrediction&quot; | 任意の文字列 |
| `LEAF_COL` | リーフインデックスの列名。これは、各ツリー内の各インスタンスの予測リーフインデックスであり、事前順序トラバーサルによって生成されます。 | &quot;&quot; | 任意の文字列 |
| `FEATURE_SUBSET_STRATEGY` | 各ツリーノードで分割するために考慮される機能の数。 サポートされるオプション：`auto` （タスクに基づいて自動的に決定される）、`all` （すべてのフィーチャを使用）、`onethird` （フィーチャ数の 3 分の 1 を使用）、`sqrt` （フィーチャ数の平方根を使用）、`log2` （フィーチャ数の二乗を使用）、`n` （ここで n は、`(0, 1]` の範囲内のフィーチャの一部、または `[1, total number of features]` の範囲内の特定の数のフィーチャです）。 | &quot;auto&quot; | `auto`, `all`, `onethird`, `sqrt`, `log2`, `n` |
| `WEIGHT_COL` | 列名（例：重み）。 設定されていない場合や空の場合は、すべてのインスタンスの重みが `1.0` として扱われます。 | 設定されていません | 任意の文字列 |
| `LOSS_TYPE` | [!DNL Gradient Boosted Tree] モデルが最小化しようとしている損失関数。 | 「ロジスティック」 | `logistic` （大文字と小文字を区別しない） |
| `STEP_SIZE` | 範囲 `(0, 1]` のステップサイズ （学習率とも呼ばれます）は、各推定量の貢献度を小さくするために使用されます。 | 0.1 | （>= 0.0, &lt;= 1） |
| `MAX_ITER` | アルゴリズムの最大反復数。 | 20 | （>= 0） |
| `SUBSAMPLING_RATE` | 各デシジョンツリーのトレーニングに使用されるトレーニングデータの割合。 値の範囲は 0 &lt; 値 &lt;= 1 にする必要があります。 | 1.0 | `(0, 1]` |
| `PROBABILITY_COL` | 予測されるクラスの条件付き確率の列名。 メモ：すべてのモデルが適切に調整された確率を出力するわけではありません。これらは正確な確率ではなく信頼性スコアとして扱う必要があります。 | 「確率」 | 任意の文字列 |
| `ONE_VS_REST` | マルチクラス分類で、このアルゴリズムの One-vs-Rest のラッピングを有効または無効にします。 | `false` | `true`、`false` |

{style="table-layout:auto"}

**例**

```sql
Create MODEL modelname OPTIONS(
  type = 'gradient_boosted_tree_classifier'
) AS
  select col1, col2, col3 from training-dataset
```

## [!DNL Linear Support Vector Classifier] （LinearSVC） {#linear-support-vector-classifier}

[!DNL Linear Support Vector Classifier] （LinearSVC）は、高次元空間においてデータを分類するためにハイパープレーンを構築する。 クラス間のマージンを最大化して分類エラーを最小限に抑えるために使用できます。

**パラメーター**

[!DNL Linear Support Vector Classifier (LinearSVC)] のパフォーマンスの設定および最適化のための主要なパラメーターの概要を次の表に示します。

| パラメーター | 説明 | デフォルト値 | 可能な値 |
|--------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------|------------------------------------------------------------------------------------------------------|
| `MAX_ITER` | アルゴリズムを実行する最大反復数。 | 100 | （>= 0） |
| `AGGREGATION_DEPTH` | ツリーの集約の深度。 このパラメーターは、ネットワーク通信のオーバーヘッドを減らすために使用されます。 | 2 | 任意の正の整数 |
| `FIT_INTERCEPT` | インターセプト項に適合するかどうか。 | `true` | `true`、`false` |
| `TOL` | このパラメーターは、繰り返しを停止するしきい値を決定します。 | 1E-6 | （>= 0） |
| `MAX_BLOCK_SIZE_IN_MB` | 入力データをブロックにスタックするための最大メモリ（MB 単位）です。 パラメーターを `0` に設定した場合、最適な値が自動的に選択されます（通常は 1 MB 程度）。 | 0.0 | （>= 0） |
| `REG_PARAM` | 正規化パラメーターは、モデルの複雑さを制御し、オーバーフィットを防ぐのに役立ちます。 | 0.0 | （>= 0） |
| `STANDARDIZATION` | このパラメータは、モデルを適合させる前にトレーニング機能を標準化するかどうかを示します。 | `true` | `true`、`false` |
| `PREDICTION_COL` | 予測出力の列名。 | 「予測」 | 任意の文字列 |
| `RAW_PREDICTION_COL` | 生の予測値の列名（信頼性とも呼ばれます）。 | &quot;rawPrediction&quot; | 任意の文字列 |
| `ONE_VS_REST` | マルチクラス分類で、このアルゴリズムの One-vs-Rest のラッピングを有効または無効にします。 | `false` | `true`、`false` |

{style="table-layout:auto"}

**例**

```sql
Create MODEL modelname OPTIONS(
  type = 'linear_svc_classifier'
) AS
  select col1, col2, col3 from training-dataset
```

## [!DNL Logistic Regression] {#logistic-regression}

[!DNL Logistic Regression] は、バイナリ分類タスクに使用される監視対象アルゴリズムです。 インスタンスがクラスに属する確率をロジスティック関数を使用してモデル化し、より高い確率でそのインスタンスをクラスに割り当てます。 これにより、データを 2 つのカテゴリのいずれかに分離することが目標となる問題に適しています。

**パラメーター**

[!DNL Logistic Regression] のパフォーマンスの設定と最適化のための主要なパラメーターの概要を次の表に示します。

| パラメーター | 説明 | デフォルト値 | 可能な値 |
|----------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------|----------------|
| `MAX_ITER` | アルゴリズムが実行するイテレーションの最大数。 | 100 | （>= 0） |
| `REGPARAM` | 正規化パラメーターは、モデルの複雑さを制御するために使用します。 | 0.0 | （>= 0） |
| `ELASTICNETPARAM` | `ElasticNet` 混合パラメータは、L1 （ラッソ）ペナルティと L2 （リッジ）ペナルティのバランスを制御します。 値が 0 の場合は L2 ペナルティ （係数のサイズを小さくするリッジ）が適用され、値が 1 の場合は L1 ペナルティ （係数の一部をゼロに設定してスパースを促進するラッソ）が適用されます。 | 0.0 | （>= 0, &lt;= 1） |

{style="table-layout:auto"}

**例**

```sql
Create MODEL modelname OPTIONS(
  type = 'logistic_reg'
) AS
  select col1, col2, col3 from training-dataset
```

## [!DNL Multilayer Perceptron Classifier] {#multilayer-perceptron-classifier}

[!DNL Multilayer Perceptron Classifier] （MLPC）は、フィードフォワード人工ニューラルネットワーク分類器です。 複数のノードの完全に接続されたレイヤーで構成され、各ノードは入力の重み付けされた線形の組み合わせを適用し、その後にアクティブ化関数が適用されます。 MLPC は、非線形の決定境界を必要とする複雑な分類タスクに使用されます。

**パラメーター**

| パラメーター | 説明 | デフォルト値 | 可能な値 |
|-----------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------|------------------------------------------|
| `MAX_ITER` | アルゴリズムを実行する最大反復数。 | 100 | （>= 0） |
| `BLOCK_SIZE` | 入力データをパーティション内の行列に積み重ねるためのブロック・サイズ。 ブロック・サイズがパーティション内の残りのデータを超える場合は、それに応じて調整されます。 | 128 | （>= 0） |
| `STEP_SIZE` | 最適化の各反復に使用されるステップサイズ （ソルバー `gd` ードにのみ適用）。 | 0.03 | （> 0） |
| `TOL` | 最適化の収束許容値。 | `1E-6` | （>= 0） |
| `PREDICTION_COL` | 予測出力の列名。 | 「予測」 | 任意の文字列 |
| `SEED` | アルゴリズム内のランダムプロセスを制御するためのランダムシード。 | 設定されていません | 任意の 64 ビット番号 |
| `PROBABILITY_COL` | 予測されるクラスの条件付き確率の列名。 これらは、正確な確率ではなく信頼性スコアとして扱う必要があります。 | 「確率」 | 任意の文字列 |
| `RAW_PREDICTION_COL` | 生の予測値の列名（信頼性とも呼ばれます）。 | &quot;rawPrediction&quot; | 任意の文字列 |
| `ONE_VS_REST` | マルチクラス分類で、このアルゴリズムの One-vs-Rest のラッピングを有効または無効にします。 | `false` | `true`、`false` |

{style="table-layout:auto"}

**例**

```sql
CREATE MODEL modelname OPTIONS(
  type = 'multilayer_perceptron_classifier'
) AS
  select col1, col2, col3 from training-dataset
```

## [!DNL Naive Bayes Classifier] {#naive-bayes-classifier}

[!DNL Naive Bayes Classifier] は、特性間の強い（素朴な）独立性前提を持つベイズの定理に基づく単純な確率論的、マルチクラス分類子です。 各ラベルに付与された各機能の条件付確率分布を計算するために、トレーニングデータを 1 回のパスで計算することで、効率的にトレーニングを行います。 予測には、ベイズの定理を使用して、観測が与えられた各ラベルの条件付き確率分布を計算します。

**パラメーター**

| パラメーター | 説明 | デフォルト値 | 可能な値 |
|------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------|------------------------------------------------|
| `MODEL_TYPE` | モデルタイプを指定します。 サポートされるオプションは、`"multinomial"`、`"complement"`、`"bernoulli"`、`"gaussian"` です。 モデルタイプでは大文字と小文字が区別されます。 | 「多項式」 | `"multinomial"`、`"complement"`、`"bernoulli"`、`"gaussian"` |
| `SMOOTHING` | スムージング パラメータは、カテゴリ データのゼロ周波数の問題を処理するために使用されます。 | 1.0 | （>= 0） |
| `PROBABILITY_COL` | このパラメーターは、予測されたクラスの条件付き確率の列名を指定します。 メモ：すべてのモデルが適切に調整された確率推定値を提供するわけではありません。これらの値は正確な確率ではなく確信として扱います。 | 「確率」 | 任意の文字列 |
| `WEIGHT_COL` | インスタンスの重み付けの列名。 設定されていない場合や空の場合は、すべてのインスタンスの重みが `1.0` として扱われます。 | 設定されていません | 任意の文字列 |
| `PREDICTION_COL` | 予測出力の列名。 | 「予測」 | 任意の文字列 |
| `RAW_PREDICTION_COL` | 生の予測値の列名（信頼性とも呼ばれます）。 | &quot;rawPrediction&quot; | 任意の文字列 |
| `ONE_VS_REST` | マルチクラス分類に対して One-vs-Rest を有効にするかどうかを指定します。 | `false` | `true`、`false` |

{style="table-layout:auto"}

**例**

```sql
CREATE MODEL modelname OPTIONS(
  type = 'naive_bayes_classifier'
) AS
  SELECT col1, col2, col3 FROM training-dataset
```

## [!DNL Random Forest Classifier] {#random-forest-classifier}

[!DNL Random Forest Classifier] は、トレーニング中に複数のデシジョンツリーを構築するアンサンブル学習アルゴリズムです。 予測を平均化し、分類タスクのために大部分の木によって選択されたクラスを選択することによって、過剰適合を軽減します。

**パラメーター**

| パラメーター | 説明 | デフォルト値 | 可能な値 |
|-------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------|------------------------------------------------------------------------------------------------------|
| `MAX_BINS` | bin の最大数は、連続する機能を個別の間隔に分割する方法を決定します。 これは、各デシジョンツリーノードでの機能の分割方法に影響します。 bin が多いほど、精度が高くなります。 | 32 | 少なくとも 2 で、カテゴリ機能のカテゴリ数以上である必要があります。 |
| `CACHE_NODE_IDS` | `false` の場合、アルゴリズムによってツリーがエグゼキューターに渡され、インスタンスとノードが一致します。 `true` の場合、アルゴリズムはインスタンスごとにノード ID をキャッシュするので、トレーニングが高速化されます。 | `false` | `true`、`false` |
| `CHECKPOINT_INTERVAL` | キャッシュされたノード ID のチェックポイント頻度を指定します。 例えば、`10` は、キャッシュが 10 回ごとにチェックポイントされることを意味します。 | 10 | （>= 1） |
| `IMPURITY` | 情報ゲインの計算に使用する条件（大文字と小文字を区別しない）。 | 「ジニ」 | `entropy`、`gini` |
| `MAX_DEPTH` | ツリーの最大深度（負でない）。 例えば、depth `0` は 1 つのリーフノードを意味し、depth `1` は 1 つの内部ノードと 2 つのリーフノードを意味します。 | 5 | （>= 0） |
| `MIN_INFO_GAIN` | 分割がツリーノードで考慮されるために必要な最小情報利得。 | 0.0 | （>= 0.0） |
| `MIN_WEIGHT_FRACTION_PER_NODE` | 各子が分割の後に持つ必要がある重み付けされたサンプル数の最小割合。 分割によって、いずれかの子の合計重みの割合がこの値を下回った場合、その子は破棄されます。 | 0.0 | （>= 0.0, &lt;= 0.5） |
| `MIN_INSTANCES_PER_NODE` | 分割後に各子に必要なインスタンスの最小数。 分割の結果、この値よりもインスタンス数が少ない場合、分割は破棄されます。 | 1 | （>= 1） |
| `MAX_MEMORY_IN_MB` | ヒストグラム集計に割り当てる最大メモリを MB 単位で指定します。 この値が小さすぎる場合、1 回のイテレーションで分割されるノードは 1 つだけで、その集計はこのサイズを超える可能性があります。 | 256 | （>= 1） |
| `PREDICTION_COL` | 予測出力の列名。 | 「予測」 | 任意の文字列 |
| `WEIGHT_COL` | 列名（例：重み）。 設定されていない場合や空の場合は、すべてのインスタンスの重みが `1.0` として扱われます。 | 設定されていません | 任意の有効な列名または空 |
| `SEED` | アルゴリズム内のランダムプロセスの制御に使用されるランダムシードです。 | -1689246527 | 任意の 64 ビット番号 |
| `BOOTSTRAP` | ツリーを構築する際にブートストラップサンプルを使用するかどうか。 | `true` | `true`、`false` |
| `NUM_TREES` | トレーニングする木の数。 `1` の場合、ブートストラップは使用されません。 `1` より大きい場合は、ブートストラップが適用されます。 | 20 | （>= 1） |
| `SUBSAMPLING_RATE` | 各決定ツリーの学習に使用されるトレーニングデータの割合。 | 1.0 | （> 0, &lt;= 1） |
| `LEAF_COL` | リーフインデックスの列名。この名前には、各ツリー内の各インスタンスの予測リーフインデックスが順不同で含まれます。 | &quot;&quot; | 任意の文字列 |
| `PROBABILITY_COL` | 予測されるクラスの条件付き確率の列名。 これらは、正確な確率ではなく信頼性スコアとして扱う必要があります。 | 設定されていません | 任意の文字列 |
| `RAW_PREDICTION_COL` | 生の予測値の列名（信頼性とも呼ばれます）。 | &quot;rawPrediction&quot; | 任意の文字列 |
| `ONE_VS_REST` | マルチクラス分類に対して One-vs-Rest を有効にするかどうかを指定します。 | `false` | `true`、`false` |

{style="table-layout:auto"}

**例**

```sql
Create MODEL modelname OPTIONS(
  type = 'random_forest_classifier'
) AS
  select col1, col2, col3 from training-dataset
```

## 次の手順

このドキュメントでは、様々な分類アルゴリズムの設定および使用方法を確認しました。 次に、他のタイプの高度な統計モデルについて詳しくは、[&#x200B; 回帰 &#x200B;](./regression.md) および [&#x200B; クラスタリング &#x200B;](./clustering.md) に関するドキュメントを参照してください。
