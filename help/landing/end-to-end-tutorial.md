---
keywords: Experience Platform;ホーム;人気のトピック;CJA;ジャーニー分析;Customer Journey Analytics;キャンペーンオーケストレーション;オーケストレーション;カスタマージャーニー;ジャーニー;ジャーニーオーケストレーション;機能;地域
title: Adobe Experience Platformのエンドツーエンドのワークフロー例
description: Adobe Experience Platformの基本的なエンドツーエンドのワークフローを大まかに説明します。
exl-id: 0a4d3b68-05a5-43ef-bf0d-5738a148aa77
source-git-commit: f9917d6a6de81f98b472cff9b41f1526ea51cdae
workflow-type: tm+mt
source-wordcount: '1832'
ht-degree: 12%

---

# Adobe Experience Platformのエンドツーエンドのサンプルワークフロー

Adobe Experience Platform は、顧客体験を促進する完全なソリューションを構築し、管理するための、市場で最も強力で柔軟性の高いオープンシステムです。Platform を使用すると、組織は顧客データとコンテンツを任意のシステムから一元管理し、データサイエンスと機械学習を適用して、パーソナライズされた豊富なエクスペリエンスのデザインと配信を大幅に改善できます。

RESTful API を基に構築された Platform は、システムの全機能を開発者に公開し、使い慣れたツールを使用してエンタープライズソリューションを簡単に統合できるようにします。 Platform では、顧客データを取り込み、ターゲットに設定するオーディエンスにデータをセグメント化し、これらのオーディエンスを外部の宛先にアクティブ化することで、顧客の全体像を導き出すことができます。 次のチュートリアルでは、エンドツーエンドのワークフローを示し、ソースを介した取り込みから、宛先を介したオーディエンスのアクティベーションまでのすべての手順を示します。

![Experience Platformのエンドツーエンドのワークフロー](./images/end-to-end-tutorial/platform-end-2-end-workflow.png)

## はじめに

このエンドツーエンドのワークフローは、複数のAdobe Experience Platformサービスを使用します。 次に、このワークフローで使用されるサービスの概要へのリンクのリストを示します。

- [[!DNL Experience Data Model (XDM)]](../xdm/home.md)：[!DNL Platform] が、カスタマーエクスペリエンスデータを整理する際に使用する、標準化されたフレームワーク。セグメント化を最大限に活用するには、[データモデリングのベストプラクティス](../xdm/schema/best-practices.md)に従って、データがプロファイルとイベントとして取り込まれていることを確認してください。
- [[!DNL Identity Service]](../identity-service/home.md)：デバイスやシステム間で ID を結び付けることで、顧客とその行動の包括的なビューを提供します。
- [ソース](../sources/home.md)：[!DNL Experience Platform] を使用すると、データを様々なソースから取得しながら、[!DNL Platform] サービスを使用して受信データの構造化、ラベル付け、拡張を行うことができます。
- [[!DNL Segmentation Service]](../segmentation/home.md)：[!DNL Segmentation Service] を使用すると、[!DNL Experience Platform] に保存されている、個人（顧客、見込み客、ユーザー、組織など）に関連するデータを細かいグループに分類できます。
- [[!DNL Real-Time Customer Profile]](../profile/home.md)：複数のソースからの集計データに基づいて、統合されたリアルタイムの顧客プロファイルを提供します。
- [データセット](../catalog/datasets/overview.md)：でのデータ永続化のためのストレージと管理の構成 [!DNL Experience Platform].
- [宛先](../destinations/home.md)：宛先は、一般に使用されるアプリケーションとの事前定義済みの統合で、これを使用すると、Platform のデータをシームレスにアクティブ化してクロスチャネルマーケティングキャンペーン、メールキャンペーン、ターゲット広告およびその他の多くのユースケースを実現できます。

## XDM スキーマの作成

データを Platform に取り込む前に、まず XDM スキーマを作成して、そのデータの構造を記述する必要があります。 次の手順でデータを取り込む際に、受信データをこのスキーマにマッピングします。 XDM スキーマの例を作成する方法については、 [スキーマエディターを使用したスキーマの作成](../xdm/tutorials/create-schema-ui.md).

上記のチュートリアルでは、スキーマの ID フィールドを設定する方法を示します。 ID フィールドは、レコードまたは時系列イベントに関連する個人を識別するために使用できるフィールドを表します。 ID フィールドは、Platform で顧客 ID グラフを構築する方法に関する重要なコンポーネントで、最終的には、異なるデータフラグメントをリアルタイム顧客プロファイルが結合して顧客の全体像を把握する方法に影響します。 Platform で ID グラフを表示する方法について詳しくは、 [ID グラフビューアの使用方法](../identity-service/features/identity-graph-viewer.md).

スキーマに基づくデータから顧客プロファイルを構築できるように、リアルタイム顧客プロファイルでスキーマの使用を有効にする必要があります。 詳しくは、 [プロファイルのスキーマの有効化](../xdm/ui/resources/schemas.md#profile) （スキーマ UI ガイド）を参照してください。

## データの Platform への取り込み

XDM スキーマを作成したら、データのシステムへの取り込みを開始できます。

Platform に取り込まれたすべてのデータは、取り込み時に個々のデータセットに保存されます。 データセットは、特定の XDM スキーマにマッピングされるデータレコードのコレクションです。 でデータを使用できるようにする前に [!DNL Real-Time Customer Profile]に値を指定する場合は、該当するデータセットを具体的に設定する必要があります。 プロファイルのデータセットを有効にする方法について詳しくは、 [データセット UI ガイド](../catalog/datasets/user-guide.md#enable-profile) そして [データセット設定 API のチュートリアル](../profile/tutorials/dataset-configuration.md). データセットを設定したら、データの取り込みを開始できます。

Platform を使用すると、外部ソースからデータを取り込みながら、Platform サービスを使用して受信データの構造化、ラベル付けおよび拡張を行うことができます。アドビのアプリケーション、クラウドベースのストレージ、データベースなど、様々なソースからデータを取り込むことができます。例えば、 [Amazon S3](../sources/tutorials/api/create/cloud-storage/s3.md). 使用可能なソースの完全なリストについては、 [ソースコネクタの概要](../sources/home.md).

Amazon S3 をソースコネクタとして使用している場合は、『 API チュートリアル』の手順に従って、 [Amazon S3 コネクタの作成](../sources/tutorials/api/create/cloud-storage/s3.md) または UI チュートリアルの [Amazon S3 コネクタの作成](../sources/tutorials/ui/create/cloud-storage/s3.md) コネクタ内でデータを作成、接続、取り込む方法を説明します。

ソースコネクタの詳細な手順については、 [ソースコネクタの概要](../sources/home.md). フローサービス、ソースがベースとなる API の詳細については、 [フローサービス API リファレンス](https://www.adobe.io/experience-platform-apis/references/flow-service/).

データがソースコネクタを通じて Platform に取り込まれ、プロファイル対応データセットに保存されると、XDM スキーマに設定した ID データに基づいて顧客プロファイルが自動的に作成されます。

初めて新しいデータセットにデータをアップロードする場合、または新しい ETL プロセスやデータソースを設定する場合は、データが正しくアップロードされ、生成されたプロファイルに期待するデータが含まれていることを慎重に確認することをお勧めします。 Platform UI で顧客プロファイルにアクセスする方法について詳しくは、 [リアルタイム顧客プロファイル UI ガイド](../profile/ui/user-guide.md). リアルタイム顧客プロファイル API を使用してプロファイルにアクセスする方法について詳しくは、 [エンティティエンドポイントの使用](../profile/api/entities.md).

## データの評価

取り込んだデータからプロファイルを正常に生成したら、セグメント化を使用してデータを評価できます。 セグメント化とは、マーケティング可能な人々のグループを顧客ベースから区別するために、個人のサブセットによって共有される特定の属性や行動をプロファイルストアから定義するプロセスです。 セグメント化の詳細については、 [セグメント化サービスの概要](../segmentation/home.md).

### セグメント定義の作成

開始するには、ターゲットオーディエンスを作成するために、顧客をクラスター化するセグメント定義を作成する必要があります。 セグメント定義は、ターゲットに設定するオーディエンスを定義するために使用できる一連のルールです。 セグメント定義を作成するには、UI ガイドの「 [セグメントビルダー](../segmentation/ui/segment-builder.md) または [セグメントの作成](../segmentation/tutorials/create-a-segment.md).

セグメント定義を作成したら、必ずセグメント定義 ID をメモしておいてください。

### セグメント定義を評価する

セグメント定義を作成した後、セグメントを 1 回限りのインスタンスとして評価するセグメントジョブを作成するか、セグメントを継続的に評価するスケジュールを作成できます。

必要に応じてセグメント定義を評価するために、セグメントジョブを作成できます。 セグメントジョブは、参照されるセグメント定義と結合ポリシーに基づいて新しいオーディエンスセグメントを作成する非同期プロセスです。 結合ポリシーは、顧客プロファイルの作成に使用するデータと、ソース間に相違がある場合にどのデータが優先されるかを決定するために Platform が使用する一連のルールです。 結合ポリシーの使用方法については、「 [結合ポリシー UI ガイド](../profile/merge-policies/ui-guide.md).

セグメントジョブを作成および評価したら、オーディエンスのサイズや処理中に発生した可能性のあるエラーなど、セグメントに関する情報を取得できます。 セグメントジョブの作成方法（提供する必要のあるすべての詳細を含む）については、 [セグメントジョブ開発者ガイド](../segmentation/api/segment-jobs.md).

セグメント定義を継続的に評価するには、スケジュールを作成して有効にします。 スケジュールとは、セグメントジョブを 1 日 1 回、指定した時間に自動的に実行するために使用できるツールです。 スケジュールを作成して有効にする方法については、API ガイドの手順に従ってください ( [スケジュールエンドポイント](../segmentation/api/schedules.md).

## 評価済みデータのエクスポート

1 回限りのセグメントジョブや継続的なスケジュールを作成したら、セグメントエクスポートジョブを作成して結果をデータセットにエクスポートしたり、結果を宛先にエクスポートしたりできます。 以下の節では、これら両方のオプションに関するガイダンスを示します。

### 評価したデータをデータセットにエクスポート

1 回限りのセグメントジョブまたは継続的なスケジュールを作成した後、セグメントの書き出しジョブを作成して結果を書き出すことができます。 セグメント書き出しジョブは、評価されたオーディエンスに関する情報をデータセットに送信する非同期タスクです。

書き出しジョブを作成する前に、まずデータの書き出し先のデータセットを作成する必要があります。 データセットの作成方法については、 [target データセットの作成](../segmentation/tutorials/evaluate-a-segment.md#create-dataset) セグメントの評価に関するチュートリアルで、作成後にデータセット ID を必ずメモしておきます。 データセットを作成した後に、書き出しジョブを作成できます。 書き出しジョブの作成方法については、API ガイドの手順に従ってください ( [ジョブエンドポイントを書き出し](../segmentation/api/export-jobs.md).

### 評価したデータを宛先に書き出す

または、1 回限りのセグメントジョブや継続的なスケジュールを作成した後で、結果を宛先に書き出すこともできます。 宛先とは、オーディエンスをアクティブ化して配信できる、外部サービスのAdobeアプリケーションなどのエンドポイントです。 使用可能な宛先の完全なリストについては、 [宛先カタログ](../destinations/catalog/overview.md).

バッチまたは電子メールマーケティングの宛先に対してデータをアクティブ化する方法については、 [Platform UI を使用して、オーディエンスデータをバッチプロファイル書き出し先にアクティブ化する方法](../destinations/ui/activate-batch-profile-destinations.md) そして [フローサービス API を使用したバッチ宛先への接続とデータのアクティブ化の方法に関するガイド](../destinations/api/connect-activate-batch-destinations.md).

## Platform データアクティビティの監視

Platform では、データフロー（Platform の様々なコンポーネント間でデータを移動するジョブの表現）を使用して、データの処理方法を追跡できます。 これらのデータフローは、異なるサービスをまたいで設定され、ソースコネクタからターゲットデータセットにデータを移動し、で利用するのに役立ちます。 [!DNL Identity Service] および [!DNL Real-Time Customer Profile] を追加してから、最終的に宛先に対してアクティブ化する必要があります。 監視ダッシュボードは、データフローのジャーニーを視覚的に表します。 Platform UI 内でデータフローを監視する方法については、 [ソースのデータフローの監視](../dataflows/ui/monitor-sources.md) および [宛先のデータフローの監視](../dataflows/ui/monitor-destinations.md).

また、 [!DNL Observability Insights]. Platform UI を通じてアラート通知を購読したり、設定済みの Webhook に送信したりできます。 Experience PlatformUI から使用可能なアラートを表示、有効、無効、サブスクライブする方法について詳しくは、 [[!UICONTROL アラート] UI ガイド](../observability/alerts/ui.md). Web フックを通じてアラートを受け取る方法の詳細については、 [Adobe I/Oイベント通知の購読中](../observability/alerts/subscribe.md).

## 次の手順

このチュートリアルでは、Platform の簡単なエンドツーエンドフローの基本的な紹介を受けました。 Adobe Experience Platformの詳細については、 [Platform の概要](./home.md). Platform UI と Platform API の使用について詳しくは、 [Platform UI ガイド](./ui-guide.md) そして [Platform API ガイド](./api-guide.md) それぞれ。
